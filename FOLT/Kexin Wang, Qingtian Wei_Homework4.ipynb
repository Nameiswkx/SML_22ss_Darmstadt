{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework 4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nummer: 2540047, 2455213\n",
    "name: Kexin Wang, Qingtian Wei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a). We picked up the 20 words, which start with *'dis'* and do not start with *'dis'*  from positive and negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|     |  positive  |  negative   | sum  |\n",
    "|:----:|:----:|:----:|:----:|\n",
    "| starts with *‘dis’* | 0 | 5 | 5 |\n",
    "| does not start with *‘dis’* | 10 | 5 | 15 |\n",
    "| sum  | 10 | 10 | 20 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b). \n",
    "<font size = 4>P(negative sentiment| starts with *'dis'*) =$  \\frac{negative \\ sentiment \\ starts\\ with\\ 'dis' }{positive\\ and\\ negative\\ sentiment\\ starts\\ with\\ 'dis'} = \\frac{5}{0+5} = 1 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of the words starting with \"dis\" with negative meaning in whole opinion_lexicon corpus:  242\n",
      "The count of the words starting with \"dis\" with positive meaning in whole opinion_lexicon corpus:  3\n",
      "The probability that a word starting with \"dis\" has negative sentiment is  0.9877551020408163\n",
      "As we seen, the probability that a word starting with \"dis\" has negative sentiment is pretty high, and there is only 3 words with positive meanig starting with \"dis\" in whole opinion_lexicon corpus. Therefore, the hypothesis that words starting with \"dis\" most likely express negative sentiment. \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import opinion_lexicon\n",
    "\n",
    "negative = nltk.corpus.opinion_lexicon.words('negative-words.txt')\n",
    "positive = nltk.corpus.opinion_lexicon.words('positive-words.txt')\n",
    "\n",
    "count_dis_neg = []\n",
    "count_dis_pos = []\n",
    "\n",
    "for word in negative:\n",
    "    if word.startswith(\"dis\"):\n",
    "        count_dis_neg.append(word)\n",
    "for word in positive:\n",
    "    if word.startswith(\"dis\"):\n",
    "        count_dis_pos.append(word)\n",
    "\n",
    "a = len(count_dis_neg)/(len(count_dis_neg)+len(count_dis_pos))      \n",
    "print('The count of the words starting with \"dis\" with negative meaning in whole opinion_lexicon corpus: ' ,len(count_dis_neg ))\n",
    "print('The count of the words starting with \"dis\" with positive meaning in whole opinion_lexicon corpus: ' ,len(count_dis_pos ))\n",
    "print('The probability that a word starting with \"dis\" has negative sentiment is ' , a)  \n",
    "print('As we seen, the probability that a word starting with \"dis\" has negative sentiment is pretty high, and there is only 3 words with positive meanig starting with \"dis\" in whole opinion_lexicon corpus. Therefore, the hypothesis that words starting with \"dis\" most likely express negative sentiment. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " adventure\n",
      "[(('could', 'see'), 24), (('miss', 'langford'), 18), (('blue', 'throat'), 16), (('two', 'men'), 14), (('let', 'go'), 13), (('mary', 'jane'), 12), (('shook', 'head'), 11), (('big', 'man'), 10), (('years', 'ago'), 9), (('long', 'time'), 9)]\n",
      " belles_lettres\n",
      "[(('new', 'york'), 59), (('united', 'states'), 51), (('bang', 'jensen'), 31), (('nineteenth', 'century'), 25), (('mrs', 'coolidge'), 23), (('even', 'though'), 22), (('civil', 'war'), 19), (('years', 'ago'), 19), (('one', 'day'), 18), (('science', 'fiction'), 18)]\n",
      " editorial\n",
      "[(('united', 'states'), 56), (('new', 'york'), 24), (('mr', 'podger'), 21), (('west', 'berlin'), 20), (('per', 'cent'), 19), (('president', 'kennedy'), 18), (('united', 'nations'), 18), (('east', 'greenwich'), 18), (('last', 'year'), 17), (('mr', 'kennedy'), 14)]\n",
      " fiction\n",
      "[(('miss', 'ada'), 19), (('linda', 'kay'), 17), (('bobby', 'joe'), 16), (('could', 'see'), 14), (('mr', 'jack'), 14), (('old', 'man'), 13), (('simms', 'purdew'), 12), (('big', 'hans'), 12), (('new', 'york'), 10), (('uncle', 'randolph'), 9)]\n",
      " government\n",
      "[(('united', 'states'), 137), (('rhode', 'island'), 75), (('fiscal', 'year'), 54), (('du', 'pont'), 44), (('peace', 'corps'), 41), (('general', 'motors'), 40), (('small', 'business'), 39), (('new', 'york'), 33), (('states', 'america'), 25), (('sam', 'rayburn'), 24)]\n",
      " hobbies\n",
      "[(('new', 'york'), 27), (('per', 'head'), 20), (('chemical', 'name'), 18), (('drug', 'chemical'), 17), (('years', 'ago'), 16), (('per', 'day'), 15), (('interior', 'design'), 15), (('united', 'states'), 14), (('milligrams', 'per'), 12), (('nuclear', 'weapons'), 11)]\n",
      " humor\n",
      "[(('mr', 'crombie'), 10), (('mr', 'blatz'), 9), (('general', 'burnside'), 9), (('years', 'ago'), 7), (('burnside', 'horse'), 7), (('mr', 'gorboduc'), 7), (('humor', 'comedy'), 6), (('los', 'angeles'), 5), (('one', 'said'), 5), (('police', 'captain'), 4)]\n",
      " learned\n",
      "[(('af', 'af'), 129), (('per', 'cent'), 37), (('united', 'states'), 36), (('dominant', 'stress'), 31), (('let', 'us'), 26), (('wage', 'rate'), 25), (('index', 'words'), 24), (('middle', 'class'), 22), (('pulmonary', 'artery'), 21), (('index', 'word'), 21)]\n",
      " lore\n",
      "[(('united', 'states'), 44), (('new', 'york'), 31), (('high', 'school'), 27), (('per', 'cent'), 25), (('anti', 'semitism'), 22), (('part', 'time'), 17), (('years', 'ago'), 16), (('white', 'house'), 15), (('middle', 'class'), 15), (('economic', 'integration'), 15)]\n",
      " mystery\n",
      "[(('mr', 'skyros'), 22), (('mrs', 'meeker'), 15), (('prime', 'minister'), 13), (('went', 'back'), 10), (('old', 'man'), 10), (('could', 'see'), 10), (('door', 'open'), 9), (('new', 'york'), 8), (('last', 'night'), 8), (('station', 'wagon'), 8)]\n",
      " news\n",
      "[(('new', 'york'), 54), (('per', 'cent'), 50), (('mr', 'mrs'), 42), (('united', 'states'), 40), (('last', 'year'), 36), (('last', 'week'), 36), (('white', 'house'), 29), (('year', 'old'), 28), (('high', 'school'), 24), (('president', 'kennedy'), 24)]\n",
      " religion\n",
      "[(('jesus', 'christ'), 22), (('new', 'members'), 22), (('lo', 'shu'), 21), (('st', 'john'), 20), (('new', 'birth'), 16), (('years', 'ago'), 14), (('born', 'god'), 14), (('new', 'england'), 13), (('real', 'estate'), 11), (('anti', 'slavery'), 11)]\n",
      " reviews\n",
      "[(('new', 'york'), 31), (('last', 'night'), 20), (('mr', 'white'), 10), (('mr', 'sansom'), 10), (('field', 'marshal'), 9), (('saturday', 'night'), 8), (('mr', 'kennedy'), 8), (('per', 'cent'), 8), (('dr', 'keys'), 8), (('world', 'war'), 7)]\n",
      " romance\n",
      "[(('old', 'man'), 30), (('could', 'see'), 16), (('mike', 'deegan'), 14), (('new', 'york'), 13), (('poor', 'john'), 11), (('cousin', 'elec'), 11), (('go', 'back'), 10), (('young', 'men'), 10), (('next', 'morning'), 10), (('mrs', 'kirby'), 10)]\n",
      " science_fiction\n",
      "[(('half', 'man'), 9), (('said', 'hal'), 7), (('lady', 'da'), 7), (('shell', 'people'), 6), (('water', 'brother'), 4), (('first', 'time'), 4), (('hal', 'yarrow'), 4), (('would', 'longer'), 4), (('fusion', 'power'), 4), (('super', 'condamine'), 4)]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import string\n",
    "\n",
    "#brown.words(categories= 'adventure')\n",
    "punctuation = ['!','\"','#','$','%','&',\"'\",'(',')','*','+',',','-','.','/',':',';','<','=','>','?','@','[','\\\\',']','^','_','`','{','|','}','~','``',\"''\",'--']\n",
    "\n",
    "def count_10(file):\n",
    "    lower_words = [x.lower() for x in file]\n",
    "#    pun_stop = punctuation + stopwords.words('english')\n",
    "\n",
    "    for c in punctuation:\n",
    "        lower_words = str(lower_words).replace(c, ' ')\n",
    "    words = lower_words.split()   \n",
    "    filter_words1 = [x for x in words if x not in stopwords.words('english')]\n",
    "    filter_words = list(filter(lambda x: x.isalpha() and len(x) > 1, filter_words1)) # remove numbers and single letter words\n",
    "    filter_words = list(nltk.bigrams(filter_words))\n",
    "    fdist1 = nltk.FreqDist(filter_words)\n",
    "    return (fdist1.most_common(10))\n",
    "\n",
    "w = list(brown.categories())\n",
    "for a in w:\n",
    "    print('', a)\n",
    "    print(count_10(brown.words(categories=a)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework 4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English ('u', 'n') -> 0.0063174114021571645\n",
      "English ('n', 'i') -> 0.004930662557781202\n",
      "English ('i', 'v') -> 0.0032357473035439137\n",
      "English ('v', 'e') -> 0.01140215716486903\n",
      "English ('e', 'r') -> 0.020338983050847456\n",
      "English ('r', 's') -> 0.003389830508474576\n",
      "English ('s', 'a') -> 0.001694915254237288\n",
      "English ('a', 'l') -> 0.019106317411402157\n",
      "English ('d', 'e') -> 0.00600924499229584\n",
      "English ('e', 'c') -> 0.007087827426810477\n",
      "German_Deutsch ('d', 'i') -> 0.0099361249112846\n",
      "German_Deutsch ('i', 'e') -> 0.016465578424414477\n",
      "German_Deutsch ('a', 'l') -> 0.008232789212207239\n",
      "German_Deutsch ('l', 'l') -> 0.005961674946770759\n",
      "German_Deutsch ('l', 'g') -> 0.00127750177430802\n",
      "German_Deutsch ('g', 'e') -> 0.02185947480482612\n",
      "German_Deutsch ('e', 'm') -> 0.0055358410220014195\n",
      "German_Deutsch ('m', 'e') -> 0.006813342796309439\n",
      "German_Deutsch ('e', 'i') -> 0.02995031937544358\n",
      "German_Deutsch ('i', 'n') -> 0.01973030518097942\n",
      "Finnish_Suomi ('i', 'h') -> 0.0037654653039268424\n",
      "Finnish_Suomi ('h', 'm') -> 0.002555137170521786\n",
      "Finnish_Suomi ('m', 'i') -> 0.011565357719203874\n",
      "Finnish_Suomi ('i', 's') -> 0.03388918773534158\n",
      "Finnish_Suomi ('s', 'o') -> 0.0034965034965034965\n",
      "Finnish_Suomi ('o', 'i') -> 0.013717052178590641\n",
      "Finnish_Suomi ('i', 'k') -> 0.01681011296395912\n",
      "Finnish_Suomi ('k', 'e') -> 0.01277568585260893\n",
      "Finnish_Suomi ('e', 'u') -> 0.008606777837547068\n",
      "Finnish_Suomi ('u', 'k') -> 0.007530930607853685\n",
      "Italian ('d', 'i') -> 0.0317743132887899\n",
      "Italian ('i', 'c') -> 0.009651076466221232\n",
      "Italian ('c', 'h') -> 0.005642167780252413\n",
      "Italian ('h', 'i') -> 0.0014847809948032665\n",
      "Italian ('i', 'a') -> 0.009651076466221232\n",
      "Italian ('a', 'r') -> 0.012472160356347439\n",
      "Italian ('r', 'a') -> 0.009651076466221232\n",
      "Italian ('a', 'z') -> 0.006829992576095026\n",
      "Italian ('z', 'i') -> 0.010987379361544172\n",
      "Italian ('i', 'o') -> 0.015738678544914626\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import udhr\n",
    "\n",
    "languages = ['English', 'German_Deutsch', 'Finnish_Suomi', 'Italian']\n",
    "language_base = dict((language, udhr.words(language + '-Latin1')) for language in languages)\n",
    "\n",
    "def build_language_models(languages, words):\n",
    "    \n",
    "    cfd = nltk.ConditionalFreqDist((lang, char)\n",
    "                                   for lang in languages \n",
    "                                   for word in language_base[lang]\n",
    "                                   for char in nltk.bigrams(word.lower()))\n",
    "    \n",
    "    return cfd\n",
    "\n",
    "language_model_cfd = build_language_models(languages, language_base)\n",
    "\n",
    "\n",
    "\n",
    "# print the models for visual inspection\n",
    "for language in languages:\n",
    "    for key in list(language_model_cfd[language].keys())[:10]:\n",
    "        print(language, key, \"->\", language_model_cfd[language].freq(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English ('U', 'n') -> 0.0009244992295839754\n",
      "English ('n', 'i') -> 0.004930662557781202\n",
      "English ('i', 'v') -> 0.0032357473035439137\n",
      "English ('v', 'e') -> 0.01140215716486903\n",
      "English ('e', 'r') -> 0.020338983050847456\n",
      "English ('r', 's') -> 0.003389830508474576\n",
      "English ('s', 'a') -> 0.001694915254237288\n",
      "English ('a', 'l') -> 0.01848998459167951\n",
      "English ('D', 'e') -> 0.0009244992295839754\n",
      "English ('e', 'c') -> 0.007087827426810477\n",
      "German_Deutsch ('D', 'i') -> 0.0008516678495386799\n",
      "German_Deutsch ('i', 'e') -> 0.016465578424414477\n",
      "German_Deutsch ('A', 'l') -> 0.00113555713271824\n",
      "German_Deutsch ('l', 'l') -> 0.005961674946770759\n",
      "German_Deutsch ('l', 'g') -> 0.00127750177430802\n",
      "German_Deutsch ('g', 'e') -> 0.01760113555713272\n",
      "German_Deutsch ('e', 'm') -> 0.005393896380411639\n",
      "German_Deutsch ('m', 'e') -> 0.0042583392476933995\n",
      "German_Deutsch ('e', 'i') -> 0.028956706884315116\n",
      "German_Deutsch ('i', 'n') -> 0.019304471256210078\n",
      "Finnish_Suomi ('I', 'H') -> 0.00026896180742334586\n",
      "Finnish_Suomi ('H', 'M') -> 0.00026896180742334586\n",
      "Finnish_Suomi ('M', 'I') -> 0.00026896180742334586\n",
      "Finnish_Suomi ('I', 'S') -> 0.0010758472296933835\n",
      "Finnish_Suomi ('S', 'O') -> 0.00026896180742334586\n",
      "Finnish_Suomi ('O', 'I') -> 0.00026896180742334586\n",
      "Finnish_Suomi ('I', 'K') -> 0.00026896180742334586\n",
      "Finnish_Suomi ('K', 'E') -> 0.00026896180742334586\n",
      "Finnish_Suomi ('E', 'U') -> 0.00026896180742334586\n",
      "Finnish_Suomi ('U', 'K') -> 0.0004034427111350188\n",
      "Italian ('D', 'I') -> 0.0002969561989606533\n",
      "Italian ('I', 'C') -> 0.00014847809948032666\n",
      "Italian ('C', 'H') -> 0.00014847809948032666\n",
      "Italian ('H', 'I') -> 0.00014847809948032666\n",
      "Italian ('I', 'A') -> 0.00014847809948032666\n",
      "Italian ('A', 'R') -> 0.00014847809948032666\n",
      "Italian ('R', 'A') -> 0.0002969561989606533\n",
      "Italian ('A', 'Z') -> 0.00014847809948032666\n",
      "Italian ('Z', 'I') -> 0.00014847809948032666\n",
      "Italian ('I', 'O') -> 0.00014847809948032666\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import udhr\n",
    "languages = ['English', 'German_Deutsch', 'Finnish_Suomi', 'Italian']\n",
    "language_base = dict((language, udhr.words(language + '-Latin1')) for language in languages)\n",
    "\n",
    "def build_language_models(languages, words):\n",
    "    cfd = nltk.ConditionalFreqDist((lang, bc) \n",
    "                                  for lang in languages \n",
    "                                   for word in language_base[lang]\n",
    "                                   for bc in nltk.bigrams(word))\n",
    "        \n",
    "    return cfd \n",
    "\n",
    "language_model_cfd = build_language_models(languages, language_base)\n",
    "\n",
    "\n",
    "\n",
    "        #print(language, key, language_model_cfd[language].freq(key))\n",
    "for language in languages:\n",
    "    for key in list(language_model_cfd[language].keys())[:10]:\n",
    "        print(language, key, \"->\", language_model_cfd[language].freq(key))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guess the language of text1 is \n",
      " [((1, 'German_Deutsch-Latin1'), -2.867132867132867), ((0, 'English-Latin1'), -1.7202797202797204), ((3, 'Italian-Latin1'), -0.7818181818181817), ((2, 'Finnish_Suomi-Latin1'), -0.05594405594405605)]\n",
      "The above results show that for text1, the last one is Finnish_Suomi, which means text1 is Finnish_Suomi\n",
      "\n",
      "guess the language of text2 is [((2, 'Finnish_Suomi-Latin1'), -0.1066176470588236), ((3, 'Italian-Latin1'), 0.5640350877192982), ((1, 'German_Deutsch-Latin1'), 0.792772444946358), ((0, 'English-Latin1'), 0.8125352907961604)]\n",
      "The above results show that for text2, the last one is English, which means text2 is English\n",
      "\n",
      "guess the language of text3 is [((2, 'Finnish_Suomi-Latin1'), 0.2964285714285714), ((1, 'German_Deutsch-Latin1'), 0.4362745098039216), ((0, 'English-Latin1'), 0.5857843137254901), ((3, 'Italian-Latin1'), 0.9031862745098039)]\n",
      "The above results show that for text3, the last one is Italian, which means text3 is Italian\n",
      "\n",
      "guess the language of text4 is [((1, 'German_Deutsch-Latin1'), -0.034055727554179516), ((3, 'Italian-Latin1'), 0.3544117647058823), ((2, 'Finnish_Suomi-Latin1'), 0.42500000000000004), ((0, 'English-Latin1'), 0.6563467492260062)]\n",
      "The above results show that for text4, the last one is English, which means text4 is English\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ★ With the help of a multilingual corpus such as the Universal Declaration of Human Rights Corpus (nltk.corpus.udhr), and NLTK's frequency distribution and rank correlation functionality (nltk.FreqDist, nltk.spearman_correlation), develop a system that guesses the language of a previously unseen text. For simplicity, work with a single character encoding and just a few languages.\n",
    "\n",
    "import re\n",
    "\n",
    "from nltk import *\n",
    "from nltk.corpus import udhr\n",
    "from nltk.corpus import genesis\n",
    "from nltk import spearman_correlation\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "languages = []\n",
    "\n",
    "def process_text(text):\n",
    "\n",
    "\n",
    "    text = [list(word.lower()) for word in text if word.isalpha()]\n",
    "    text = [item for sublist in text for item in sublist]\n",
    "    fre_text = FreqDist(text)\n",
    "    text_ranks = list(ranks_from_sequence(fre_text))\n",
    "\n",
    "    return text_ranks\n",
    "\n",
    "def prep_language_corpus(fids):\n",
    "    languages = [fileid for fileid in fids if re.findall('Latin1', fileid)]\n",
    "    udhr_corpus = [[list(word.lower()) for word in udhr.words(language) if word.isalpha()] for language in languages]\n",
    "    udhr_corpus = [[item for sublist in language for item in sublist] for language in udhr_corpus]\n",
    "    languages = list(enumerate(languages))\n",
    "    language_freq_dists = [FreqDist(language) for language in udhr_corpus]\n",
    "    language_ranks = [list(ranks_from_sequence(dist)) for dist in language_freq_dists]\n",
    "\n",
    "    return languages, language_ranks\n",
    "# We inquired some information, including some information from google and Natural Language Processing with Python 2nd.version.\n",
    "#\\cite{https://www.bookstack.cn/read/nlp-py-2e-zh/spilt.11.3.md}\n",
    "#\\cite{https://github.com/ygnoh/nltk3-study}\n",
    "#\\cite{https://github.com/walshbr}\n",
    "# We noticed that most of the predicted position texts use Spearman's rank correlation for statistics\n",
    "# so we also tried to use this coefficient to calculate the correlation.\n",
    "def spearman(text_ranks, language_ranks):\n",
    "    spearman_numbers = []\n",
    "    for language in language_ranks:\n",
    "        number = spearman_correlation(language, text_ranks)\n",
    "        spearman_numbers.append(number)\n",
    "\n",
    "    return spearman_numbers\n",
    "\n",
    "def calculate(text, fids):\n",
    "    \n",
    "    languages, language_ranks = prep_language_corpus(fids)\n",
    "    mystery_ranks = process_text(text)\n",
    "    spearman_numbers = spearman(text_ranks, language_ranks)\n",
    "    zipped = list(zip(languages, spearman_numbers))\n",
    "    zipped = sorted(zipped, key=lambda x: x[1])\n",
    "    #here we sorted it all by spearman correlation.\n",
    "    # and print the highest one which will print at last, which means the last one is the best one for matching.\n",
    "    return zipped\n",
    "\n",
    "fids = ['English-Latin1', 'German_Deutsch-Latin1','Finnish_Suomi-Latin1', 'Italian-Latin1' ]\n",
    "\n",
    "text1 = \"Syksy on kaunis vuodenaika, varsinkin kun ei sada.\"\n",
    "text2 = \"Erkenntnisfortschritte ergeben sich durch das Wechselspiel von Beobachtung oder Experiment mit der Theorie.\"\n",
    "text3 = \"Come in altri paesi europei del mediterraneo, sono presenti tratti distintivi ed elementi che caratterizzano la dieta mediterranea.\"\n",
    "text4 = \"A healthy diet is important if you want to live a healthy life.\"\n",
    "print('guess the language of text1 is \\n', guess_language(text1, fids))\n",
    "print(\"The above results show that for text1, the last one is Finnish_Suomi, which means text1 is Finnish_Suomi\\n\")\n",
    "print('guess the language of text2 is', guess_language(text2, fids))\n",
    "\n",
    "print(\"The above results show that for text2, the last one is English, which means text2 is English\\n\")\n",
    "print('guess the language of text3 is', guess_language(text3, fids))\n",
    "\n",
    "print(\"The above results show that for text3, the last one is Italian, which means text3 is Italian\\n\")\n",
    "print('guess the language of text4 is', guess_language(text4, fids))\n",
    "\n",
    "print(\"The above results show that for text4, the last one is English, which means text4 is English\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
