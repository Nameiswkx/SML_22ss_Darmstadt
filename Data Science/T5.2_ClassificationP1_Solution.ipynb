{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science 1 - Tutorial 5.2 - Classification Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 1 shows the dataset showing the characteristics of a tumor mass with their respective labels (Benign or Malignant). A colleague proposed a cancer (malignant tumor) detector that outputs the class Malignant if the Radius>5 and Area>5, and the class Benign otherwise. Calculate the accuracy, precision, recall, specificity, F1 score, and balanced accuracy of this detector. \n",
    "\n",
    "\n",
    "<center><b>Table 1: Tumor data and labels</b></center>\n",
    "\n",
    "| Radius | Perimeter | Area | Category | \n",
    "| --- | --- | --- | --- |\n",
    "| 5 | 1 | 1 | Benign |\n",
    "| 5 | 4 | 5 | Benign |\n",
    "| 3 | 1 | 1 | Benign |\n",
    "| 6 | 8 | 1 | Benign |\n",
    "| 4 | 1 | 3 | Benign |\n",
    "| 8 | 10 | 8 | Malignant |\n",
    "| 1 | 1 | 1 | Benign |\n",
    "| 2 | 2 | 1 | Benign |\n",
    "| 2 | 1 | 1 | Benign |\n",
    "| 4 | 1 | 1 | Benign |\n",
    "| 1 | 1 | 1 | Benign |\n",
    "| 2 | 1 | 1 | Benign |\n",
    "| 5 | 3 | 3 | Malignant |\n",
    "| 1 | 1 | 1 | Benign |\n",
    "| 8 | 5 | 10 | Malignant |\n",
    "| 7 | 6 | 4 | Malignant |\n",
    "| 4 | 1 | 1 | Benign |\n",
    "| 4 | 1 | 1 | Benign |\n",
    "| 10 | 7 | 6 | Malignant |\n",
    "| 6 | 1 | 1 | Benign |\n",
    "| 7 | 2 | 10 | Malignant |\n",
    "| 10 | 5 | 3 | Malignant |\n",
    "| 3 | 1 | 1 | Benign |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A**: With the classifier output:\n",
    "\n",
    "| Radius | Perimeter | Area | Category | Classifier Output\n",
    "| --- | --- | --- | --- | --- \n",
    "| 5 | 1 | 1 | Benign | B\n",
    "| 5 | 4 | 5 | Benign | B\n",
    "| 3 | 1 | 1 | Benign | B\n",
    "| 6 | 8 | 1 | Benign | B\n",
    "| 4 | 1 | 3 | Benign | B\n",
    "| 8 | 10 | 8 | Malignant | M\n",
    "| 1 | 1 | 1 | Benign | B\n",
    "| 2 | 2 | 1 | Benign | B\n",
    "| 2 | 1 | 1 | Benign | B\n",
    "| 4 | 1 | 1 | Benign | B\n",
    "| 1 | 1 | 1 | Benign | B\n",
    "| 2 | 1 | 1 | Benign | B\n",
    "| 5 | 3 | 3 | Malignant | B\n",
    "| 1 | 1 | 1 | Benign | B\n",
    "| 8 | 5 | 10 | Malignant | M\n",
    "| 7 | 6 | 4 | Malignant | B\n",
    "| 4 | 1 | 1 | Benign | B\n",
    "| 4 | 1 | 1 | Benign | B\n",
    "| 10 | 7 | 6 | Malignant | M\n",
    "| 6 | 1 | 1 | Benign | B\n",
    "| 7 | 2 | 10 | Malignant | M\n",
    "| 10 | 5 | 3 | Malignant | B\n",
    "| 3 | 1 | 1 | Benign | B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = 16\n",
    "FN = 3\n",
    "TP = 4\n",
    "FP = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8695652173913043"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy ACC \n",
    "(TP+TN)/(TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision PR\n",
    "TP/(TP+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall RE aka Sensitivity\n",
    "RE=TP/(TP+FN)\n",
    "RE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specificity SP\n",
    "SP = TN/(TN+FP)\n",
    "SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7272727272727273"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1 Score \n",
    "2*TP/(2*TP+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7857142857142857"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balanced accuracy BACC\n",
    "(RE+SP)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes' Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printer failures are associated with three types of problems: hardware, software, and other (such as connectors), with probabilities 0.1, 0.6, and 0.3, respectively. The probability of a printer failure given a hardware problem is 0.9, given a software problem is 0.2, and given any other problem is 0.5. If a customer enters the manufacturerâ€™s Web site to diagnose a printer failure, what is the most likely cause of the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A**:\n",
    "\n",
    "Given a printer failure, we want to decide which is the most likely cause: hardware (H), software (S), or other (O). So we need to calculate the values of $P(H|F)$,  $P(S|F)$, and  $P(O|F)$.\n",
    "\n",
    "We calculate the denominator first: \n",
    "\n",
    "\\begin{align*}\n",
    "\tP(F) & =P(F|H)P(H)+P(F|S)P(S)+P(F|O)P(O)\\\\\n",
    "\t& =0.9\\times0.1+0.2\\times0.6+0.5\\times0.3=0.36\n",
    "\\end{align*}\n",
    "\n",
    "Then by Bayes' theorem:\n",
    "\n",
    "\\begin{align*}\n",
    "\tP(H|F) & =\\frac{P(F|H)P(H)}{P(F)}=\\frac{0.9\\times0.1}{0.36}=0.250\\\\\n",
    "\tP(S|F) & =\\frac{P(F|S)P(S)}{P(F)}=\\frac{0.2\\times0.6}{0.36}=0.333\\\\\n",
    "\tP(O|F) & =\\frac{P(F|O)P(O)}{P(F)}=\\frac{0.5\\times0.3}{0.36}=0.417\n",
    "\\end{align*}\n",
    "\n",
    "Since $P(O|F)$ is the largest, the most likely cause of the problem in the other category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Is the (ID3) decision tree algorithm that we saw in the lecture a greedy algorithm? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A**: The algorithm is a greedy algorithm because at each iteration it selects the best attribute to split the samples based on the information gain using the impurity measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Still using the dataset in Table 1, discretize all the numerical features into $\\leq5$ and $>5$ and derive the decision tree using the ID3 algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23045174023136175"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "15/23 *(-14/15*np.log2(14/15)-1/15*np.log2(1/15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2821836954640462"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8/23 *(-2/8*np.log2(2/8)-6/8*np.log2(6/8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5127"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.2305+0.2822"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.613359296578276"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "19/23 *(-15/19*np.log2(15/19)-4/19*np.log2(4/19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1410918477320231"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4/23 *(-1/4*np.log2(1/4)-3/4*np.log2(3/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7545"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.6134+0.1411"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5198145762288982"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "19/23 *(-16/19*np.log2(16/19)-3/19*np.log2(3/19))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Radius | Perimeter | Area | Category | \n",
    "| --- | --- | --- | --- |\n",
    "| 5 | 1 | 1 | Benign |\n",
    "| 5 | 4 | 5 | Benign |\n",
    "| 3 | 1 | 1 | Benign |\n",
    "| 4 | 1 | 3 | Benign |\n",
    "| 1 | 1 | 1 | Benign |\n",
    "| 2 | 2 | 1 | Benign |\n",
    "| 2 | 1 | 1 | Benign |\n",
    "| 4 | 1 | 1 | Benign |\n",
    "| 1 | 1 | 1 | Benign |\n",
    "| 2 | 1 | 1 | Benign |\n",
    "| 5 | 3 | 3 | Malignant |\n",
    "| 1 | 1 | 1 | Benign |\n",
    "| 4 | 1 | 1 | Benign |\n",
    "| 4 | 1 | 1 | Benign |\n",
    "| 3 | 1 | 1 | Benign |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35335933502142136"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "15/15 *(-14/15*np.log2(14/15)-1/15*np.log2(1/15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Radius | Perimeter | Area | Category | \n",
    "| --- | --- | --- | --- |\n",
    "| 6 | 8 | 1 | Benign |\n",
    "| 8 | 10 | 8 | Malignant |\n",
    "| 8 | 5 | 10 | Malignant |\n",
    "| 7 | 6 | 4 | Malignant |\n",
    "| 10 | 7 | 6 | Malignant |\n",
    "| 6 | 1 | 1 | Benign |\n",
    "| 7 | 2 | 10 | Malignant |\n",
    "| 10 | 5 | 3 | Malignant |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4056390622295664"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4/8 *(-1/4*np.log2(1/4)-3/4*np.log2(3/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4/8 *(-2/4*np.log2(2/4)-2/4*np.log2(2/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8112"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4056*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Area $\\leq5$\n",
    "\n",
    "| Radius | Perimeter | Area | Category | \n",
    "| --- | --- | --- | --- |\n",
    "| 6 | 8 | 1 | Benign |\n",
    "| 7 | 6 | 4 | Malignant |\n",
    "| 6 | 1 | 1 | Benign |\n",
    "| 10 | 5 | 3 | Malignant |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2/4 *(-1/2*np.log2(1/2)-1/2*np.log2(1/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"P53.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lagrange Multiplier\n",
    "\n",
    "In the lecture we saw the following standard quadratic optimization\n",
    "problem:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\underset{\\boldsymbol{w}}{\\text{minimize}}\\frac{1}{2}\\left\\Vert \\boldsymbol{w}\\right\\Vert ^{2}\\\\\n",
    "\\text{subject to }\\forall j,\\;y^{(j)}\\left(\\boldsymbol{w}^{\\intercal}\\boldsymbol{x}^{(j)}+w_{0}\\right) & \\geq1.\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In finding the optimal hyperplane, we can convert the optimization\n",
    "problem to an unconstrained problem using Lagrange multipliers $\\alpha^{(j)}$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "L_{p} & =\\frac{1}{2}\\left\\Vert \\boldsymbol{w}\\right\\Vert ^{2}-\\sum_{j}\\alpha^{(j)}\\left\\{ y^{(j)}\\left(\\boldsymbol{w}^{\\intercal}\\boldsymbol{x}^{(j)}+w_{0}\\right)-1\\right\\} \\\\\n",
    " & =\\frac{1}{2}\\left(\\boldsymbol{w}^{\\intercal}\\boldsymbol{w}\\right)-\\boldsymbol{w}^{\\intercal}\\sum_{j}\\alpha^{(j)}y^{(j)}\\boldsymbol{x}^{(j)}-w_{0}\\sum_{j}\\alpha^{(j)}y^{(j)}+\\sum_{j}\\alpha^{(j)}\n",
    "\\end{align}\n",
    "$$ \n",
    "\n",
    "for $j=1,\\ldots,n$ samples. This should be minimized w.r.t. $\\boldsymbol{w},w_{0}$\n",
    "and maximized w.r.t. $\\alpha^{(j)}\\geq0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Find the partial derivatives of $ L_{p} $ with respect to $ \\boldsymbol{w} $ and $ w_{0} $ and set them to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A**: \n",
    "\n",
    "$ \\frac{\\partial L_{p}}{\\partial\\boldsymbol{w}}=0\\Rightarrow\\boldsymbol{w}=\\sum_{j}\\alpha^{(j)}y^{(j)}\\boldsymbol{x}^{(j)} $ <br/> $ \\frac{\\partial L_{p}}{\\partial w_{0}}=0\\Rightarrow\\sum_{j}\\alpha^{(j)}y^{(j)}=0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Since the main minimization problem and the linear constraints are convex, we can solve the dual problem. Plug the the equations you get into $L_{p}$, which now we call the dual $L_{d}$,such that you don't see the terms $\\boldsymbol{w}$ or $w_{0}$ anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A**:\n",
    "\n",
    "\\begin{align}\n",
    "L_{d} & =\\frac{1}{2}\\left(\\boldsymbol{w}^{\\intercal}\\boldsymbol{w}\\right)-\\boldsymbol{w}^{\\intercal}\\sum_{j}\\alpha^{(j)}y^{(j)}\\boldsymbol{x}^{(j)}-w_{0}\\sum_{j}\\alpha^{(j)}y^{(j)}+\\sum_{j}\\alpha^{(j)}\\\\\n",
    " &=\\frac{1}{2}\\left(\\boldsymbol{w}^{\\intercal}\\boldsymbol{w}\\right)-\\boldsymbol{w}^{\\intercal}\\boldsymbol{w}+\\sum_{j}\\alpha^{(j)}\\\\\n",
    " & =-\\frac{1}{2}\\left(\\boldsymbol{w}^{\\intercal}\\boldsymbol{w}\\right)+\\sum_{j}\\alpha^{(j)}\\\\\n",
    " & =-\\frac{1}{2}\\sum_{j}\\sum_{k}\\alpha^{(j)}\\alpha^{(k)}y^{(j)}y^{(k)}\\left(\\boldsymbol{x}^{(j)}\\right)^{\\intercal}\\boldsymbol{x}^{(k)}+\\sum_{j}\\alpha^{(j)}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Research: What is the dual problem, what are the constraints? What values of $\\alpha$'s do the support vectors take? What are the values of the $\\alpha$'s for the rest of the samples?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A**:\n",
    "\n",
    "The dual problem is maximizing $L_d$ w.r.t. $ \\alpha^{(j)} $,subject to the constraints $ \\sum_{j}\\alpha^{(j)}y^{(j)}=0 $ and $ \\alpha^{(j)}\\geq0 $, $\\forall j=1,\\ldots,n$. There will be $n$ of $ \\alpha $'s, but most will vanish with $ \\alpha^{(j)}=0 $ and only the support vectors have $ \\alpha^{(j)}>0 $.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Given two samples $ \\boldsymbol{x}^{(1)}=\\left(2,2\\right),\\boldsymbol{x}^{(2)}=\\left(5,6\\right)$ with labels $y$ equal to +1 and -1 respectively. By using the information that the lagrange multipliers can be obtained from: $$ \\alpha^{(1)}=\\alpha^{(2)}=\\frac{2}{\\left(x_{1}^{(1)}-x_{1}^{(2)}\\right)^{2}+\\left(x_{2}^{(1)}-x_{2}^{\\left(2\\right)}\\right)^{2}},$$ find the optimal separating plane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A**:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\t\t\t\t\t\\alpha^{(1)} & = & \\alpha^{(2)}=\\frac{2}{\\left(2-5\\right)^{2}+\\left(2-6\\right)^{2}}=\\frac{2}{9+16}=\\frac{2}{25}\\\\\n",
    "\t\t\t\t\t\\boldsymbol{w} & = & \\sum_{j}\\alpha^{(j)}y^{(j)}\\mathbf{x}^{(j)}=\\frac{2}{25}\\cdot1\\cdot\\left[\\begin{array}{c}\n",
    "\t\t\t\t\t\t2\\\\\n",
    "\t\t\t\t\t\t2\n",
    "\t\t\t\t\t\\end{array}\\right]+\\frac{2}{25}\\cdot\\left(-1\\right)\\cdot\\left[\\begin{array}{c}\n",
    "\t\t\t\t\t\t5\\\\\n",
    "\t\t\t\t\t\t6\n",
    "\t\t\t\t\t\\end{array}\\right]=\\frac{2}{25}\\left[\\begin{array}{c}\n",
    "\t\t\t\t\t\t-3\\\\\n",
    "\t\t\t\t\t\t-4\n",
    "\t\t\t\t\t\\end{array}\\right]\\\\\n",
    "\t\t\t\t\tw_{0} & = & 1-\\boldsymbol{w}^{\\intercal}\\boldsymbol{x}^{(1)}=1-\\frac{2}{25}\\left[\\begin{array}{cc}\n",
    "\t\t\t\t\t\t-3 & -4\\end{array}\\right]\\cdot\\left[\\begin{array}{c}\n",
    "\t\t\t\t\t\t2\\\\\n",
    "\t\t\t\t\t\t2\n",
    "\t\t\t\t\t\\end{array}\\right]=1-\\frac{2}{25}\\left(-14\\right)=\\frac{53}{25}.\n",
    "\t\t\t\t\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. In the lecture, we saw the samples whose two classes are linearly separable. In the case where there is no hyperplane to separate the classes, look for one that gives the least error. This is called the soft margin hyperplane and we define slack variables $\\xi^{(j)} \\geq0$ for $j=1,2,\\ldots,n$ samples. Research: Write down the new optimization problem. What are the values of $ \\xi^{(j)} $ that correspond to the data points within the margin, and the misclassified data points?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A**:\n",
    "\n",
    "\\begin{align}\n",
    "\t\t\\underset{\\boldsymbol{w}}{\\text{minimize}}\\frac{1}{2}\\left\\Vert \\boldsymbol{w}\\right\\Vert ^{2}+C\\cdot\\sum_{j}\\xi^{(j)}\\\\\n",
    "\t\t\\text{subject to }\\forall j,\\;y^{(j)}\\left(\\boldsymbol{w}^{\\intercal}\\boldsymbol{x}^{(j)}+w_{0}\\right) & \\geq1-\\xi^{(j)}.\n",
    "\\end{align}\n",
    "\n",
    "* $0\\leq\\xi^{(j)}\\leq1$: the data point j is within the margin. \n",
    "* $\\xi^{(j)}>1$: the data point is misclassified.\n",
    "* $C>0$: soft-margin SVM.\n",
    "\n",
    "In sklearn: $C$ is the regularization parameter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
