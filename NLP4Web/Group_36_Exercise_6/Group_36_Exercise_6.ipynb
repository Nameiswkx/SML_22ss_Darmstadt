{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP and the Web - WS 21/22 Home Exercise 6 \n",
    "\n",
    "## Regarding type hints:\n",
    "\n",
    "We tried to make the description of the parameters as clear as possible. However, if you believe that something is missing, please reach out to us in Moodle and we will try to help you out. \n",
    "We provide type hints for function parameters and return values of functions that you have to implement in the tasks. These are suggestions only, and you may use different types if you prefer. As long as you produce the required output in a coherent and understandable way, you can get full points. \n",
    "We use the term 'array-like object' to loosely refer to collection types like lists, arrays, maps, dataframes, etc.\n",
    "\n",
    "## Regarding documentation:\n",
    "\n",
    "Please use comments where appropriate to help tutors understand your code. This is especially important for the more extensive exercises later on. We also strongly encourage you to use type hints.\n",
    "\n",
    "## Regarding output of results:\n",
    "\n",
    "Please pay attention to output results (e.g. with `print()` or `display()`) when we ask you to in a task. It is your choice how you output results, but for dataframes we recommend the use of `display(df)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, you have learned how to vectorize text, how to train classifiers and how to do IR. In this exercise we look at a more practical use case: Community Question Answering (cQA). \n",
    "\n",
    "The web is full of rich ressources where humans can post questions and answers to specific topics (e.g. https://stackexchange.com/, https://quora.com or https://answers.yahoo.com/). In many cases the information need of a user is not entirely new, but a similar question has already been asked and answered in some form.\n",
    "\n",
    "\n",
    "The data is a small sample of the SemEval2015 Task 3. The data comes from a Qatar Living Forum.  This subset comes as '\\t' seperated file and includes multiple columns:\n",
    "* **qid** is the unique ID for each question\n",
    "* **cid** is the unique ID for each comment\n",
    "* **question_category** is the category of the question (such as \"Beauty and Style\")\n",
    "* **question_subject** is the subject associated with a question\n",
    "* **question** is the textual question\n",
    "* **comment** is a comment for this question\n",
    "* **comment_gold** is the label, whether this comment is a \"good\" or \"bad\" answer to the question\n",
    "\n",
    "Each comment is represented as a single row, each question can come with multiple comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.1.0/en_core_web_md-3.1.0-py3-none-any.whl (45.4 MB)\n",
      "     |████████████████████████████████| 45.4 MB 16.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /opt/conda/lib/python3.9/site-packages (from en-core-web-md==3.1.0) (3.1.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.26.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.4.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.0.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (4.62.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.6.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.4.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.21.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.7.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (21.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /opt/conda/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (60.1.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.9.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in /opt/conda/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (8.0.13)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.0.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.0.6)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /opt/conda/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (4.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.0.1)\n",
      "Installing collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.1.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import spacy\n",
    "\n",
    "#download the language model if you haven't already (you may have to restart your Python kernel)\n",
    "#spacy.cli.download(\"en_core_web_md\")\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 : Data Preprocessing- 5 Points\n",
    "\n",
    "**a)** Load the train and dev set. Lowercase the fields`question_category`, `question_subject`, `question` and `comment` of both data splits. After lowercasing, use `display` to output the `head()` of the training split and development split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>cid</th>\n",
       "      <th>question_category</th>\n",
       "      <th>question_subject</th>\n",
       "      <th>question</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>Q1_C1</td>\n",
       "      <td>beauty and style</td>\n",
       "      <td>massage oil</td>\n",
       "      <td>where i can buy good oil for massage?</td>\n",
       "      <td>i've done it once at the sharq village &amp; spa ....</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1</td>\n",
       "      <td>Q1_C4</td>\n",
       "      <td>beauty and style</td>\n",
       "      <td>massage oil</td>\n",
       "      <td>where i can buy good oil for massage?</td>\n",
       "      <td>you might be able to find body massage oil in ...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q1</td>\n",
       "      <td>Q1_C5</td>\n",
       "      <td>beauty and style</td>\n",
       "      <td>massage oil</td>\n",
       "      <td>where i can buy good oil for massage?</td>\n",
       "      <td>hi. according to your body nature in your pict...</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1</td>\n",
       "      <td>Q1_C6</td>\n",
       "      <td>beauty and style</td>\n",
       "      <td>massage oil</td>\n",
       "      <td>where i can buy good oil for massage?</td>\n",
       "      <td>oh sorry. iam stupied also, your ?where? my an...</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q17</td>\n",
       "      <td>Q17_C1</td>\n",
       "      <td>doha shopping</td>\n",
       "      <td>rolex watch</td>\n",
       "      <td>i have a rolex oyster perpetual watch day-date...</td>\n",
       "      <td>go to 51 east (either in city centre or in al ...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid     cid question_category question_subject  \\\n",
       "0   Q1   Q1_C1  beauty and style      massage oil   \n",
       "1   Q1   Q1_C4  beauty and style      massage oil   \n",
       "2   Q1   Q1_C5  beauty and style      massage oil   \n",
       "3   Q1   Q1_C6  beauty and style      massage oil   \n",
       "4  Q17  Q17_C1     doha shopping      rolex watch   \n",
       "\n",
       "                                            question  \\\n",
       "0              where i can buy good oil for massage?   \n",
       "1              where i can buy good oil for massage?   \n",
       "2              where i can buy good oil for massage?   \n",
       "3              where i can buy good oil for massage?   \n",
       "4  i have a rolex oyster perpetual watch day-date...   \n",
       "\n",
       "                                             comment comment_gold  \n",
       "0  i've done it once at the sharq village & spa ....          Bad  \n",
       "1  you might be able to find body massage oil in ...         Good  \n",
       "2  hi. according to your body nature in your pict...          Bad  \n",
       "3  oh sorry. iam stupied also, your ?where? my an...          Bad  \n",
       "4  go to 51 east (either in city centre or in al ...         Good  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>cid</th>\n",
       "      <th>question_category</th>\n",
       "      <th>question_subject</th>\n",
       "      <th>question</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q16</td>\n",
       "      <td>Q16_C1</td>\n",
       "      <td>qatar living lounge</td>\n",
       "      <td>bye bye time.. almost</td>\n",
       "      <td>it's 4:30 pm,.. almost time for me to go home....</td>\n",
       "      <td>lol md.....</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q22</td>\n",
       "      <td>Q22_C1</td>\n",
       "      <td>moving to qatar</td>\n",
       "      <td>where can i buy globe roam sim here in qatar?</td>\n",
       "      <td>can anyone tell me where can i buy globe roami...</td>\n",
       "      <td>vivo bonito, did you just cut and paste that f...</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q22</td>\n",
       "      <td>Q22_C2</td>\n",
       "      <td>moving to qatar</td>\n",
       "      <td>where can i buy globe roam sim here in qatar?</td>\n",
       "      <td>can anyone tell me where can i buy globe roami...</td>\n",
       "      <td>nkotb... i am not working to any either of the...</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q22</td>\n",
       "      <td>Q22_C3</td>\n",
       "      <td>moving to qatar</td>\n",
       "      <td>where can i buy globe roam sim here in qatar?</td>\n",
       "      <td>can anyone tell me where can i buy globe roami...</td>\n",
       "      <td>vb, i didnt say you are working with smart or ...</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q22</td>\n",
       "      <td>Q22_C9</td>\n",
       "      <td>moving to qatar</td>\n",
       "      <td>where can i buy globe roam sim here in qatar?</td>\n",
       "      <td>can anyone tell me where can i buy globe roami...</td>\n",
       "      <td>you can go to filipino souq you cab get it for...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid     cid    question_category  \\\n",
       "0  Q16  Q16_C1  qatar living lounge   \n",
       "1  Q22  Q22_C1      moving to qatar   \n",
       "2  Q22  Q22_C2      moving to qatar   \n",
       "3  Q22  Q22_C3      moving to qatar   \n",
       "4  Q22  Q22_C9      moving to qatar   \n",
       "\n",
       "                                question_subject  \\\n",
       "0                          bye bye time.. almost   \n",
       "1  where can i buy globe roam sim here in qatar?   \n",
       "2  where can i buy globe roam sim here in qatar?   \n",
       "3  where can i buy globe roam sim here in qatar?   \n",
       "4  where can i buy globe roam sim here in qatar?   \n",
       "\n",
       "                                            question  \\\n",
       "0  it's 4:30 pm,.. almost time for me to go home....   \n",
       "1  can anyone tell me where can i buy globe roami...   \n",
       "2  can anyone tell me where can i buy globe roami...   \n",
       "3  can anyone tell me where can i buy globe roami...   \n",
       "4  can anyone tell me where can i buy globe roami...   \n",
       "\n",
       "                                             comment comment_gold  \n",
       "0                                        lol md.....          Bad  \n",
       "1  vivo bonito, did you just cut and paste that f...          Bad  \n",
       "2  nkotb... i am not working to any either of the...          Bad  \n",
       "3  vb, i didnt say you are working with smart or ...          Bad  \n",
       "4  you can go to filipino souq you cab get it for...         Good  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data=pd.read_csv('500_comments_good_bad_train.tsv',sep='\\t')\n",
    "dev_data=pd.read_csv('100_comments_good_bad_dev.tsv',sep='\\t')\n",
    "\n",
    "lowerlist=['question_category', 'question_subject', 'question','comment']\n",
    "\n",
    "for name in lowerlist:\n",
    "    for i in range(len(train_data)):\n",
    "        train_data[name].iloc[i]=str(train_data[name].iloc[i].lower())\n",
    "    for j in range(len(dev_data)):\n",
    "        dev_data[name].iloc[j]=str(dev_data[name].iloc[j].lower())\n",
    "display(train_data.head())\n",
    "display(dev_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Create four new columns in the training and development splits: `category_vector`, `subject_vectors`,  `question_vectors`, `comment_vectors`. Use spaCy to convert each token of the fields `question_category`, `question_subject`, `question` and `comment` into a dense word vector (`token.vector`) and store these word vectors in the new columns. This may take a few minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>cid</th>\n",
       "      <th>question_category</th>\n",
       "      <th>question_subject</th>\n",
       "      <th>question</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_gold</th>\n",
       "      <th>category_vector</th>\n",
       "      <th>subject_vectors</th>\n",
       "      <th>question_vectors</th>\n",
       "      <th>comment_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>Q1_C1</td>\n",
       "      <td>beauty and style</td>\n",
       "      <td>massage oil</td>\n",
       "      <td>where i can buy good oil for massage?</td>\n",
       "      <td>i've done it once at the sharq village &amp; spa ....</td>\n",
       "      <td>Bad</td>\n",
       "      <td>[[0.27805, 0.41261, 0.27956, 0.022429, 0.03270...</td>\n",
       "      <td>[[0.38007, -0.51364, -0.010795, 0.013833, 0.53...</td>\n",
       "      <td>[[0.44746, 0.18366, -0.33118, -0.22959, 0.4543...</td>\n",
       "      <td>[[0.18733, 0.40595, -0.51174, -0.55482, 0.0397...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1</td>\n",
       "      <td>Q1_C4</td>\n",
       "      <td>beauty and style</td>\n",
       "      <td>massage oil</td>\n",
       "      <td>where i can buy good oil for massage?</td>\n",
       "      <td>you might be able to find body massage oil in ...</td>\n",
       "      <td>Good</td>\n",
       "      <td>[[0.27805, 0.41261, 0.27956, 0.022429, 0.03270...</td>\n",
       "      <td>[[0.38007, -0.51364, -0.010795, 0.013833, 0.53...</td>\n",
       "      <td>[[0.44746, 0.18366, -0.33118, -0.22959, 0.4543...</td>\n",
       "      <td>[[-0.11076, 0.30786, -0.5198, 0.035138, 0.1036...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q1</td>\n",
       "      <td>Q1_C5</td>\n",
       "      <td>beauty and style</td>\n",
       "      <td>massage oil</td>\n",
       "      <td>where i can buy good oil for massage?</td>\n",
       "      <td>hi. according to your body nature in your pict...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>[[0.27805, 0.41261, 0.27956, 0.022429, 0.03270...</td>\n",
       "      <td>[[0.38007, -0.51364, -0.010795, 0.013833, 0.53...</td>\n",
       "      <td>[[0.44746, 0.18366, -0.33118, -0.22959, 0.4543...</td>\n",
       "      <td>[[0.028796, 0.41306, -0.4669, -0.078175, 0.370...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1</td>\n",
       "      <td>Q1_C6</td>\n",
       "      <td>beauty and style</td>\n",
       "      <td>massage oil</td>\n",
       "      <td>where i can buy good oil for massage?</td>\n",
       "      <td>oh sorry. iam stupied also, your ?where? my an...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>[[0.27805, 0.41261, 0.27956, 0.022429, 0.03270...</td>\n",
       "      <td>[[0.38007, -0.51364, -0.010795, 0.013833, 0.53...</td>\n",
       "      <td>[[0.44746, 0.18366, -0.33118, -0.22959, 0.4543...</td>\n",
       "      <td>[[-0.44526, 0.26707, -0.64482, -0.22993, 0.142...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q17</td>\n",
       "      <td>Q17_C1</td>\n",
       "      <td>doha shopping</td>\n",
       "      <td>rolex watch</td>\n",
       "      <td>i have a rolex oyster perpetual watch day-date...</td>\n",
       "      <td>go to 51 east (either in city centre or in al ...</td>\n",
       "      <td>Good</td>\n",
       "      <td>[[0.34761, 0.033417, 0.33893, 0.13354, 0.63203...</td>\n",
       "      <td>[[-0.18472, -0.046026, 0.12382, 0.067505, 0.03...</td>\n",
       "      <td>[[0.18733, 0.40595, -0.51174, -0.55482, 0.0397...</td>\n",
       "      <td>[[0.13893, -0.019056, -0.33891, 0.12151, 0.365...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid     cid question_category question_subject  \\\n",
       "0   Q1   Q1_C1  beauty and style      massage oil   \n",
       "1   Q1   Q1_C4  beauty and style      massage oil   \n",
       "2   Q1   Q1_C5  beauty and style      massage oil   \n",
       "3   Q1   Q1_C6  beauty and style      massage oil   \n",
       "4  Q17  Q17_C1     doha shopping      rolex watch   \n",
       "\n",
       "                                            question  \\\n",
       "0              where i can buy good oil for massage?   \n",
       "1              where i can buy good oil for massage?   \n",
       "2              where i can buy good oil for massage?   \n",
       "3              where i can buy good oil for massage?   \n",
       "4  i have a rolex oyster perpetual watch day-date...   \n",
       "\n",
       "                                             comment comment_gold  \\\n",
       "0  i've done it once at the sharq village & spa ....          Bad   \n",
       "1  you might be able to find body massage oil in ...         Good   \n",
       "2  hi. according to your body nature in your pict...          Bad   \n",
       "3  oh sorry. iam stupied also, your ?where? my an...          Bad   \n",
       "4  go to 51 east (either in city centre or in al ...         Good   \n",
       "\n",
       "                                     category_vector  \\\n",
       "0  [[0.27805, 0.41261, 0.27956, 0.022429, 0.03270...   \n",
       "1  [[0.27805, 0.41261, 0.27956, 0.022429, 0.03270...   \n",
       "2  [[0.27805, 0.41261, 0.27956, 0.022429, 0.03270...   \n",
       "3  [[0.27805, 0.41261, 0.27956, 0.022429, 0.03270...   \n",
       "4  [[0.34761, 0.033417, 0.33893, 0.13354, 0.63203...   \n",
       "\n",
       "                                     subject_vectors  \\\n",
       "0  [[0.38007, -0.51364, -0.010795, 0.013833, 0.53...   \n",
       "1  [[0.38007, -0.51364, -0.010795, 0.013833, 0.53...   \n",
       "2  [[0.38007, -0.51364, -0.010795, 0.013833, 0.53...   \n",
       "3  [[0.38007, -0.51364, -0.010795, 0.013833, 0.53...   \n",
       "4  [[-0.18472, -0.046026, 0.12382, 0.067505, 0.03...   \n",
       "\n",
       "                                    question_vectors  \\\n",
       "0  [[0.44746, 0.18366, -0.33118, -0.22959, 0.4543...   \n",
       "1  [[0.44746, 0.18366, -0.33118, -0.22959, 0.4543...   \n",
       "2  [[0.44746, 0.18366, -0.33118, -0.22959, 0.4543...   \n",
       "3  [[0.44746, 0.18366, -0.33118, -0.22959, 0.4543...   \n",
       "4  [[0.18733, 0.40595, -0.51174, -0.55482, 0.0397...   \n",
       "\n",
       "                                     comment_vectors  \n",
       "0  [[0.18733, 0.40595, -0.51174, -0.55482, 0.0397...  \n",
       "1  [[-0.11076, 0.30786, -0.5198, 0.035138, 0.1036...  \n",
       "2  [[0.028796, 0.41306, -0.4669, -0.078175, 0.370...  \n",
       "3  [[-0.44526, 0.26707, -0.64482, -0.22993, 0.142...  \n",
       "4  [[0.13893, -0.019056, -0.33891, 0.12151, 0.365...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>cid</th>\n",
       "      <th>question_category</th>\n",
       "      <th>question_subject</th>\n",
       "      <th>question</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_gold</th>\n",
       "      <th>category_vector</th>\n",
       "      <th>subject_vectors</th>\n",
       "      <th>question_vectors</th>\n",
       "      <th>comment_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q16</td>\n",
       "      <td>Q16_C1</td>\n",
       "      <td>qatar living lounge</td>\n",
       "      <td>bye bye time.. almost</td>\n",
       "      <td>it's 4:30 pm,.. almost time for me to go home....</td>\n",
       "      <td>lol md.....</td>\n",
       "      <td>Bad</td>\n",
       "      <td>[[0.34761, 0.033417, 0.33893, 0.13354, 0.63203...</td>\n",
       "      <td>[[0.082178, -0.2513, -0.7495, 0.19097, 0.01664...</td>\n",
       "      <td>[[0.0013629, 0.35653, -0.055497, -0.16607, 0.0...</td>\n",
       "      <td>[[-0.44817, 0.25119, -0.43844, -0.68699, -0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q22</td>\n",
       "      <td>Q22_C1</td>\n",
       "      <td>moving to qatar</td>\n",
       "      <td>where can i buy globe roam sim here in qatar?</td>\n",
       "      <td>can anyone tell me where can i buy globe roami...</td>\n",
       "      <td>vivo bonito, did you just cut and paste that f...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>[[0.25306, 0.044859, -0.27407, -0.02257, 0.755...</td>\n",
       "      <td>[[0.44746, 0.18366, -0.33118, -0.22959, 0.4543...</td>\n",
       "      <td>[[-0.23857, 0.35457, -0.30219, 0.089559, 0.082...</td>\n",
       "      <td>[[-0.87226, 0.38091, -0.62451, 0.70442, -0.421...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q22</td>\n",
       "      <td>Q22_C2</td>\n",
       "      <td>moving to qatar</td>\n",
       "      <td>where can i buy globe roam sim here in qatar?</td>\n",
       "      <td>can anyone tell me where can i buy globe roami...</td>\n",
       "      <td>nkotb... i am not working to any either of the...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>[[0.25306, 0.044859, -0.27407, -0.02257, 0.755...</td>\n",
       "      <td>[[0.44746, 0.18366, -0.33118, -0.22959, 0.4543...</td>\n",
       "      <td>[[-0.23857, 0.35457, -0.30219, 0.089559, 0.082...</td>\n",
       "      <td>[[-0.075288, 0.30298, -0.16125, -0.081987, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q22</td>\n",
       "      <td>Q22_C3</td>\n",
       "      <td>moving to qatar</td>\n",
       "      <td>where can i buy globe roam sim here in qatar?</td>\n",
       "      <td>can anyone tell me where can i buy globe roami...</td>\n",
       "      <td>vb, i didnt say you are working with smart or ...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>[[0.25306, 0.044859, -0.27407, -0.02257, 0.755...</td>\n",
       "      <td>[[0.44746, 0.18366, -0.33118, -0.22959, 0.4543...</td>\n",
       "      <td>[[-0.23857, 0.35457, -0.30219, 0.089559, 0.082...</td>\n",
       "      <td>[[0.23403, -0.41307, 0.15722, 0.33713, 0.48818...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q22</td>\n",
       "      <td>Q22_C9</td>\n",
       "      <td>moving to qatar</td>\n",
       "      <td>where can i buy globe roam sim here in qatar?</td>\n",
       "      <td>can anyone tell me where can i buy globe roami...</td>\n",
       "      <td>you can go to filipino souq you cab get it for...</td>\n",
       "      <td>Good</td>\n",
       "      <td>[[0.25306, 0.044859, -0.27407, -0.02257, 0.755...</td>\n",
       "      <td>[[0.44746, 0.18366, -0.33118, -0.22959, 0.4543...</td>\n",
       "      <td>[[-0.23857, 0.35457, -0.30219, 0.089559, 0.082...</td>\n",
       "      <td>[[-0.11076, 0.30786, -0.5198, 0.035138, 0.1036...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid     cid    question_category  \\\n",
       "0  Q16  Q16_C1  qatar living lounge   \n",
       "1  Q22  Q22_C1      moving to qatar   \n",
       "2  Q22  Q22_C2      moving to qatar   \n",
       "3  Q22  Q22_C3      moving to qatar   \n",
       "4  Q22  Q22_C9      moving to qatar   \n",
       "\n",
       "                                question_subject  \\\n",
       "0                          bye bye time.. almost   \n",
       "1  where can i buy globe roam sim here in qatar?   \n",
       "2  where can i buy globe roam sim here in qatar?   \n",
       "3  where can i buy globe roam sim here in qatar?   \n",
       "4  where can i buy globe roam sim here in qatar?   \n",
       "\n",
       "                                            question  \\\n",
       "0  it's 4:30 pm,.. almost time for me to go home....   \n",
       "1  can anyone tell me where can i buy globe roami...   \n",
       "2  can anyone tell me where can i buy globe roami...   \n",
       "3  can anyone tell me where can i buy globe roami...   \n",
       "4  can anyone tell me where can i buy globe roami...   \n",
       "\n",
       "                                             comment comment_gold  \\\n",
       "0                                        lol md.....          Bad   \n",
       "1  vivo bonito, did you just cut and paste that f...          Bad   \n",
       "2  nkotb... i am not working to any either of the...          Bad   \n",
       "3  vb, i didnt say you are working with smart or ...          Bad   \n",
       "4  you can go to filipino souq you cab get it for...         Good   \n",
       "\n",
       "                                     category_vector  \\\n",
       "0  [[0.34761, 0.033417, 0.33893, 0.13354, 0.63203...   \n",
       "1  [[0.25306, 0.044859, -0.27407, -0.02257, 0.755...   \n",
       "2  [[0.25306, 0.044859, -0.27407, -0.02257, 0.755...   \n",
       "3  [[0.25306, 0.044859, -0.27407, -0.02257, 0.755...   \n",
       "4  [[0.25306, 0.044859, -0.27407, -0.02257, 0.755...   \n",
       "\n",
       "                                     subject_vectors  \\\n",
       "0  [[0.082178, -0.2513, -0.7495, 0.19097, 0.01664...   \n",
       "1  [[0.44746, 0.18366, -0.33118, -0.22959, 0.4543...   \n",
       "2  [[0.44746, 0.18366, -0.33118, -0.22959, 0.4543...   \n",
       "3  [[0.44746, 0.18366, -0.33118, -0.22959, 0.4543...   \n",
       "4  [[0.44746, 0.18366, -0.33118, -0.22959, 0.4543...   \n",
       "\n",
       "                                    question_vectors  \\\n",
       "0  [[0.0013629, 0.35653, -0.055497, -0.16607, 0.0...   \n",
       "1  [[-0.23857, 0.35457, -0.30219, 0.089559, 0.082...   \n",
       "2  [[-0.23857, 0.35457, -0.30219, 0.089559, 0.082...   \n",
       "3  [[-0.23857, 0.35457, -0.30219, 0.089559, 0.082...   \n",
       "4  [[-0.23857, 0.35457, -0.30219, 0.089559, 0.082...   \n",
       "\n",
       "                                     comment_vectors  \n",
       "0  [[-0.44817, 0.25119, -0.43844, -0.68699, -0.10...  \n",
       "1  [[-0.87226, 0.38091, -0.62451, 0.70442, -0.421...  \n",
       "2  [[-0.075288, 0.30298, -0.16125, -0.081987, 0.2...  \n",
       "3  [[0.23403, -0.41307, 0.15722, 0.33713, 0.48818...  \n",
       "4  [[-0.11076, 0.30786, -0.5198, 0.035138, 0.1036...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_vector=[]\n",
    "dev_vector=[]\n",
    "for name in lowerlist:\n",
    "    vector=[]\n",
    "    vec=[]\n",
    "    for i in range(len(train_data)):\n",
    "        train_doc=nlp(train_data[name].iloc[i])\n",
    "        token_vector=[]\n",
    "        for token in train_doc:\n",
    "            token_vector.append(token.vector)\n",
    "        vector.append(token_vector)\n",
    "    train_vector.append(vector)\n",
    "    \n",
    "    for m in range(len(dev_data)):\n",
    "        dev_doc=nlp(dev_data[name].iloc[m])\n",
    "        dev_token_vector=[]\n",
    "        for t in dev_doc:\n",
    "            dev_token_vector.append(t.vector)\n",
    "        vec.append(dev_token_vector)\n",
    "    dev_vector.append(vec)\n",
    "    \n",
    "vector_name=['category_vector','subject_vectors','question_vectors','comment_vectors']\n",
    "for counter, value in enumerate(vector_name):\n",
    "    train_data[value]=train_vector[counter]\n",
    "    dev_data[value]=dev_vector[counter]\n",
    "\n",
    "\n",
    "display(train_data.head())\n",
    "display(dev_data.head()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 : - Embedding and Feature Functions 11 Points\n",
    "You will train a classifier to predict whether a comment is a good answer or not, based on the word vectors. You will explore different strategies\n",
    "* how to compute a single fixed-length vector out of the word vectors\n",
    "* how to combine these single vectors from different fields (such as `question` and `comment`)\n",
    " \n",
    "**a)** Implement the function `embedding_fn_max_pooling(word_vectors)`. It should compute a single vector (of the same dimensionality as a single word vector) via max pooling: In each $i$th dimension, the resulting representation must have the maximum value based on all $i$th dimension values from all words.\n",
    "\n",
    "Example:\n",
    "\n",
    "w_0 = [0.1, 0.2, 0.3, 0.4] \n",
    "\n",
    "w_1 = [1.0, -1.5, 2.0, -2.5]\n",
    "\n",
    "The resulting embedding should be e = [max(0.1, 1.0), max(0.2, -1.5), max(0.3, 2.0), max(0.4, -2.5)] = [1.0, 0.2, 2.0, 0.4].\n",
    "\n",
    "Output the dimensionality of the resulting embedding after applying this function on the word vectors of a single question (you can choose any question)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import List, Callable\n",
    "\n",
    "def embedding_fn_max_pooling(word_vectors: List[np.array ])-> np.array:\n",
    "    \"\"\"\n",
    "    Converts an arbitrary number d-dimensional word embeddings \n",
    "    into a single d-dimensional embedding via max-pooling.\n",
    "    :params word_vectors\n",
    "        array-like object contains all dense word vectors  \n",
    "    :returns\n",
    "        d-dimensional embedding:array-like object\n",
    "    \"\"\"\n",
    "    \n",
    "    array=np.max(np.stack((word_vectors),axis=-1),axis=1)\n",
    "    return array\n",
    "\n",
    "display(embedding_fn_max_pooling(train_data['question_vectors'][0]).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Implement the function `feature_fn_concatenate_question_comment(df, embedding_fn)`. It should\n",
    "* use the `embedding_fn` to create fixed-length vectors from the fields `question_vectors` and `comment_vectors` individually. (For each sample: one vector for the question, one vector for the comments).\n",
    "* Concatenate both vectors horizontally\n",
    "* Return these concatenated vectors (the features) for all samples in the dataframe `df`.\n",
    "\n",
    "You will use these vectors to train a new classifier. Execute this function using `embedding_fn=embedding_fn_max_pooling` on the train split and output the shape of the resulting matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2324, 600)\n"
     ]
    }
   ],
   "source": [
    "def feature_fn_concatenate_question_comment(df:pd.DataFrame, embedding_fn:Callable)-> np.array:\n",
    "    \"\"\"\n",
    "    Uses the embedding_fn to create d-dimensional embeddings from the tokens \n",
    "    of the questions and comments respectively, and concatenates these embeddings.\n",
    "    :param df\n",
    "        Dataframe consisting of multiple samples. Features will be computed for each sample individually\n",
    "    :param embedding_fn\n",
    "        As in 2a)\n",
    "    :returns\n",
    "        Matrix of shape (n, d*2) whereas \n",
    "        n is the number of samples in df and \n",
    "        d*2 is the output dimensionality of the embedding_fn\n",
    "    \"\"\"\n",
    "\n",
    "        \n",
    "    new_array=np.concatenate((to_array(df['question_vectors'].map(embedding_fn)), to_array(df['comment_vectors'].map(embedding_fn))),axis=1)\n",
    "    \n",
    "    return new_array\n",
    "\n",
    "def to_array(series):\n",
    "    array=np.zeros((len(series),len(series[0])))\n",
    "    for i in range(len(series)):\n",
    "        array[i]=series[i]\n",
    "    return array\n",
    "        \n",
    "\n",
    "\n",
    "fn=feature_fn_concatenate_question_comment(train_data,embedding_fn_max_pooling)\n",
    "print(fn.shape)\n",
    "#display(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Execute the (already implemented) function `train_and_evaluate` to train a new classifier based on the two functions you implemented. Use `embedding_fn=embedding_fn_max_pooling`, `feature_fn=feature_fn_concatenate_question_comment` and leave the classifier as the default parameter. The function will normalize the computed features and train and evaluate a support vector machine.\n",
    "\n",
    "What is the advantage of using F1 macro when we want to weight each label equally, regardless of the label distribution in the dataset? Please explian the question in up to 3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.58      0.15      0.24        92\n",
      "        Good       0.80      0.97      0.88       322\n",
      "\n",
      "    accuracy                           0.79       414\n",
      "   macro avg       0.69      0.56      0.56       414\n",
      "weighted avg       0.75      0.79      0.74       414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate(df_train:pd.DataFrame, df_dev:pd.DataFrame, embedding_fn:Callable, feature_fn:Callable, \n",
    "                      classifier=make_pipeline(StandardScaler(), SVC()))->None:\n",
    "    \n",
    "    # 1) Compute vectors\n",
    "    X_train = feature_fn(df_train, embedding_fn)\n",
    "    X_dev = feature_fn(df_dev, embedding_fn)\n",
    "    \n",
    "    # 2) Train classifier\n",
    "    classifier.fit(X_train, df_train['comment_gold'])\n",
    "    \n",
    "    # 3) Predict dev data\n",
    "    predictions = classifier.predict(X_dev)\n",
    "    \n",
    "    # 4) Compute and output metrics\n",
    "    print(classification_report(df_dev['comment_gold'], predictions))\n",
    "\n",
    "df_train=train_data\n",
    "df_dev=dev_data\n",
    "train_and_evaluate(df_train, df_dev, embedding_fn_max_pooling, feature_fn_concatenate_question_comment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: It is not affected by the deviations in the distribution of the label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Create\n",
    "* one new embedding function (as in 2a) that converts multiple word vectors into a single fixed-length vector (e.g. by averaging over all word embeddings)\n",
    "* two new feature functions (as in 2b), that combine these vectors of different fields to generate the final features (e.g. add different columns, use fewer columns, use average instead of concatenating, ...).\n",
    "\n",
    "Use self-exlplanatory function names or add a comment to describe what each function does.\n",
    "\n",
    "Run a grid search (parts are already implemented) for all combinations of all two embedding functions and all three feature functions. Which combination yields the highest F1 macro? Explain in up to three sentences how the task of *question similarity* comes into play, when you want to create a basci cQA system with this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def embedding_fn_average_pooling(word_vectors: List[np.array ])-> np.array:\n",
    "    array=np.mean(np.stack((word_vectors),axis=-1),axis=1)\n",
    "    return array\n",
    "\n",
    "def feature_fn_average_question_comment(df:pd.DataFrame, embedding_fn:Callable)-> np.array:\n",
    "        \n",
    "    new_array=np.mean(np.stack((to_array(df['question_vectors'].map(embedding_fn)), to_array(df['comment_vectors'].map(embedding_fn))),axis=1),axis=1)\n",
    "    return new_array\n",
    "    \n",
    "def feature_fn_max_question_comment(df:pd.DataFrame, embedding_fn:Callable)-> np.array:\n",
    "        \n",
    "    new_array=np.max(np.stack((to_array(df['question_vectors'].map(embedding_fn)), to_array(df['comment_vectors'].map(embedding_fn))),axis=1),axis=1)\n",
    "    return new_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: max-pooling ; Features: concat-question-comment\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.58      0.15      0.24        92\n",
      "        Good       0.80      0.97      0.88       322\n",
      "\n",
      "    accuracy                           0.79       414\n",
      "   macro avg       0.69      0.56      0.56       414\n",
      "weighted avg       0.75      0.79      0.74       414\n",
      "\n",
      "Embeddings: max-pooling ; Features: average-question-comment\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.53      0.23      0.32        92\n",
      "        Good       0.81      0.94      0.87       322\n",
      "\n",
      "    accuracy                           0.78       414\n",
      "   macro avg       0.67      0.58      0.59       414\n",
      "weighted avg       0.75      0.78      0.75       414\n",
      "\n",
      "Embeddings: max-pooling ; Features: max-question-comment\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.57      0.04      0.08        92\n",
      "        Good       0.78      0.99      0.88       322\n",
      "\n",
      "    accuracy                           0.78       414\n",
      "   macro avg       0.68      0.52      0.48       414\n",
      "weighted avg       0.74      0.78      0.70       414\n",
      "\n",
      "Embeddings: average-pooling ; Features: concat-question-comment\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.67      0.34      0.45        92\n",
      "        Good       0.83      0.95      0.89       322\n",
      "\n",
      "    accuracy                           0.82       414\n",
      "   macro avg       0.75      0.65      0.67       414\n",
      "weighted avg       0.80      0.82      0.79       414\n",
      "\n",
      "Embeddings: average-pooling ; Features: average-question-comment\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.72      0.36      0.48        92\n",
      "        Good       0.84      0.96      0.90       322\n",
      "\n",
      "    accuracy                           0.83       414\n",
      "   macro avg       0.78      0.66      0.69       414\n",
      "weighted avg       0.81      0.83      0.80       414\n",
      "\n",
      "Embeddings: average-pooling ; Features: max-question-comment\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.74      0.42      0.54        92\n",
      "        Good       0.85      0.96      0.90       322\n",
      "\n",
      "    accuracy                           0.84       414\n",
      "   macro avg       0.79      0.69      0.72       414\n",
      "weighted avg       0.83      0.84      0.82       414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_functions = [\n",
    "    ('max-pooling', embedding_fn_max_pooling), \n",
    "    ('average-pooling',embedding_fn_average_pooling)\n",
    "]\n",
    "\n",
    "feature_functions = [\n",
    "    ('concat-question-comment', feature_fn_concatenate_question_comment),\n",
    "    ('average-question-comment',feature_fn_average_question_comment),\n",
    "    ('max-question-comment',feature_fn_max_question_comment)\n",
    "]\n",
    "\n",
    "for embedding_name, embedding_fn in embedding_functions:\n",
    "    for feature_name, feature_fn in feature_functions:\n",
    "        print('Embeddings:', embedding_name, '; Features:', feature_name)\n",
    "        \n",
    "        # Adjust the naming of df_train and df_dev to match your training and dev set:\n",
    "        train_and_evaluate(df_train, df_dev, embedding_fn, feature_fn)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: 1. The highest F1 macro comes from the combination of average-pooling  and max-question-comment. 2. Fristly, give our a input question and get its embedding. Now we also have the embedding of 'question_vectors',calculate the cosine-similarity with the embedding of input quesiton and each embedding of 'question_vectors',then produce a ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 : Question Similarity  - 4 Points\n",
    "\n",
    "After learning techniques regarding to community question answering. You know about the cQA pipeline:\n",
    "* Find similar questions in cQA forums. \n",
    "* Select answers addressing the information need for our question. \n",
    "* Summarize the most relevant information. \n",
    "\n",
    "Now you are designing a cQA system and are in step 1 of question similarity. Often two components are used in this step: an IR system (e.g. BM25/tf-idf) and a question re-ranker (often a neural model). \n",
    "\n",
    "Given a new question, these two components extract only the top 10 most similar already answered questions from a KB. A pool of answer candidates are taken from the answers of these extracted questions. Then useful answers from the pool of answer candidates are seleted and summarize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Explain in which order these components are executed and why usually both are used and not either one of them alone (answers can be less detailed)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The questions first go into the state of question retrieval(which is IR System) and then translate to question re-rank(often a neural model). Retrieval models often require a lot of training data, then re-ranker can be trained to produce a better ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Imagine you must select a good re-ranker for your cQA pipeline. Select a metric (of those introduced throughout this lecture), that can be used here to determine the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: We choose MRR(Mean Reciprocal Rank). The reasons are as followed: 1. This method is simple to compute and is easy to interpret. 2. This method puts a  high focus on the first relevant element of the list. It is best suitable for targeted searches like \"best item for users\". For these two reasons, we would like to choose MRR to determine the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please upload in Moodle your working Jupyter-Notebook <b>before next the lab session</b> <span style=\"color:red\">(February 10th, 16:14)</span>. Submission format: Group_No_Exercise_No.zip<br>\n",
    "Submission should contain your filled out Jupyter notebook template (naming schema: Group_No_Exercise_No.ipynb) and any auxiliar files that are necessary to run your code (e.g. datasets provided by us).<br>\n",
    "Each submission must only be handed in once per group."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
